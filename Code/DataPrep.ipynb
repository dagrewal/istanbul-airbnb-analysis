{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThe file contains the code used to preprare the datasets for the analysis files.\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "The file contains the code used to preprare the datasets for the analysis files.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library imports\n",
    "import pandas as pd; import numpy as np;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in datasets\n",
    "listings_full_df = pd.read_csv(\"../Data/listings.csv\", low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which columns have high percentages of missing data\n",
    "cols_null_50 = listings_full_df.columns[listings_full_df.isnull().mean() > .5].tolist()\n",
    "cols_null_75 = listings_full_df.columns[listings_full_df.isnull().mean() > .75].tolist()\n",
    "cols_null_100 = listings_full_df.columns[listings_full_df.isnull().mean() == 1.].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all vars that have 75% missing or above\n",
    "listings_full_df = listings_full_df.drop(cols_null_75, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which columns have no missing values\n",
    "cols_no_nulls = listings_full_df.columns[listings_full_df.isnull().mean() == 0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which columns have low cardinality\n",
    "cols_low_cardinality = listings_full_df.columns[listings_full_df.nunique() == 1].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove columns with low cardinality\n",
    "listings_full_df = listings_full_df.drop(cols_low_cardinality, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get columns needed from listings data and sort neighbourhoods into side of city\n",
    "listings_1_df = listings_full_df[['id', 'neighbourhood', 'neighbourhood_cleansed', 'smart_location', 'property_type', 'room_type']].copy()\n",
    "\n",
    "european_n = ['Fatih', 'Zeytinburnu', 'Bakirkoy', 'Kucukcekmece', 'Avcilar', 'Bahcelievler', 'Arnavutkoy', 'Bagcilar', 'Basaksehir', 'Bayrampasar', 'Besiktas',\n",
    "             'Beylikduzu', 'Beyoglu', 'Buyukcekmece', 'Catalca', 'Esenler', 'Esenyurt', 'Eyup', 'Gaziosmanpasa', 'Gungoren', 'Kagithane', 'Sariyer', 'Silivri', 'Sisli',\n",
    "             'Sultangazi']\n",
    "asian_n = ['Atasehir', 'Beykoz', 'Cekmekoy', 'Kadikoy', 'Kartal', 'Maltepe', 'Pendik', 'Sancaktepe', 'Sile', 'Sultanbeyli', 'Tuzla', 'Umraniye', 'Uskudar']\n",
    "listings_1_df['Side'] = listings_1_df.neighbourhood_cleansed.apply(lambda x: 'European' if x in european_n else 'Asian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in dataset\n",
    "calendar_df = pd.read_csv(\"../Data/calendar.csv\", low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out listings that have a min nights stay greater than 5\n",
    "calendar_fil_df = calendar_df.query(\"minimum_nights <= 5\").copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Â Convert date feature to date type and create new columns\n",
    "calendar_fil_df.date = pd.to_datetime(calendar_fil_df.date)\n",
    "calendar_fil_df['Month'] = calendar_fil_df.date.dt.month\n",
    "calendar_fil_df['MonthString'] = calendar_fil_df.Month.map({1: 'Jan', 2: 'Feb', 3: 'Mar', 4: 'Apr', 5: 'May', 6: 'Jun', 7: 'Jul', 8: 'Aug', 9: 'Sep', 10: 'Oct',\n",
    "                                                           11: 'Nov', 12: 'Dec'})\n",
    "calendar_fil_df['Year'] = calendar_fil_df.date.dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter ids that have missing price data and investigate\n",
    "id_w_missing_prices = calendar_fil_df.loc[calendar_fil_df.isnull().any(axis=1), 'listing_id'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows with missing price data\n",
    "calendar_fil_df = calendar_fil_df.dropna(subset=['price', 'adjusted_price'], how='any', axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new column that converts price to float type\n",
    "calendar_fil_df['adjusted_price_num'] = calendar_fil_df.adjusted_price.str.replace('[$,]', '').astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pivot table showing price for each month for each listing\n",
    "calendar_price_df = calendar_fil_df.pivot_table(index='listing_id', columns='MonthString', values='adjusted_price_num', aggfunc='mean').reset_index()\n",
    "calendar_price_df = calendar_price_df[['listing_id', 'Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge prepared listing and prepared calendar data ready for analysis of prices\n",
    "final_df_1 = listings_1_df.merge(calendar_price_df, how='inner', left_on='id', right_on='listing_id').drop(['listing_id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in final_df_1.select_dtypes(include='int').columns:\n",
    "    final_df_1[i] = final_df_1[i].astype('int16')\n",
    "    \n",
    "for i in final_df_1.select_dtypes(include='float').columns:\n",
    "    final_df_1[i] = final_df_1[i].astype('float16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save dataset to csv\n",
    "final_df_1.to_csv('../Data/Price_Data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter listings data and include certain columns\n",
    "listings_2_df = listings_full_df[['id', 'summary', 'description', 'neighbourhood_cleansed', 'review_scores_rating']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in dataset\n",
    "reviews_df = pd.read_csv(\"../Data/reviews.csv\", low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge prepared listings data with reviews data ready for analysis of reviews file\n",
    "final_df_2 = reviews_df.merge(listings_2_df, how='inner', left_on='listing_id', right_on='id').drop(['id_x', 'id_y'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df_2.drop(['summary', 'description', 'review_scores_rating', 'reviewer_id', 'reviewer_name'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the daaset to csv\n",
    "final_df_2.to_csv(\"../Data/Review_Data.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
