{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The file contains the code used to preprare the datasets for the analysis files.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library imports\n",
    "import pandas as pd; import numpy as np;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in datasets\n",
    "listings_full_df = pd.read_csv(\"../Data/listings.csv.gz\", low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which columns have high percentages of missing data\n",
    "cols_null_50 = listings_full_df.columns[listings_full_df.isnull().mean() > .5].tolist()\n",
    "cols_null_75 = listings_full_df.columns[listings_full_df.isnull().mean() > .75].tolist()\n",
    "cols_null_100 = listings_full_df.columns[listings_full_df.isnull().mean() == 1.].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all vars that have 75% missing or above\n",
    "listings_full_df = listings_full_df.drop(cols_null_75, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which columns have no missing values\n",
    "cols_no_nulls = listings_full_df.columns[listings_full_df.isnull().mean() == 0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which columns have low cardinality\n",
    "cols_low_cardinality = listings_full_df.columns[listings_full_df.nunique() == 1].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove columns with low cardinality\n",
    "listings_full_df = listings_full_df.drop(cols_low_cardinality, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'listing_url', 'last_scraped', 'name', 'summary', 'space',\n",
       "       'description', 'neighborhood_overview', 'transit', 'access',\n",
       "       'interaction', 'house_rules', 'picture_url', 'host_id', 'host_url',\n",
       "       'host_name', 'host_since', 'host_location', 'host_about',\n",
       "       'host_response_time', 'host_response_rate', 'host_acceptance_rate',\n",
       "       'host_is_superhost', 'host_thumbnail_url', 'host_picture_url',\n",
       "       'host_neighbourhood', 'host_listings_count',\n",
       "       'host_total_listings_count', 'host_verifications',\n",
       "       'host_has_profile_pic', 'host_identity_verified', 'street',\n",
       "       'neighbourhood', 'neighbourhood_cleansed', 'city', 'state', 'zipcode',\n",
       "       'market', 'smart_location', 'country_code', 'country', 'latitude',\n",
       "       'longitude', 'is_location_exact', 'property_type', 'room_type',\n",
       "       'accommodates', 'bathrooms', 'bedrooms', 'beds', 'bed_type',\n",
       "       'amenities', 'price', 'security_deposit', 'cleaning_fee',\n",
       "       'guests_included', 'extra_people', 'minimum_nights', 'maximum_nights',\n",
       "       'minimum_minimum_nights', 'maximum_minimum_nights',\n",
       "       'minimum_maximum_nights', 'maximum_maximum_nights',\n",
       "       'minimum_nights_avg_ntm', 'maximum_nights_avg_ntm', 'calendar_updated',\n",
       "       'availability_30', 'availability_60', 'availability_90',\n",
       "       'availability_365', 'calendar_last_scraped', 'number_of_reviews',\n",
       "       'number_of_reviews_ltm', 'first_review', 'last_review',\n",
       "       'review_scores_rating', 'review_scores_accuracy',\n",
       "       'review_scores_cleanliness', 'review_scores_checkin',\n",
       "       'review_scores_communication', 'review_scores_location',\n",
       "       'review_scores_value', 'instant_bookable', 'cancellation_policy',\n",
       "       'require_guest_profile_picture', 'require_guest_phone_verification',\n",
       "       'calculated_host_listings_count',\n",
       "       'calculated_host_listings_count_entire_homes',\n",
       "       'calculated_host_listings_count_private_rooms',\n",
       "       'calculated_host_listings_count_shared_rooms', 'reviews_per_month'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see list of columns\n",
    "listings_full_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get columns needed from listings data and sort neighbourhoods into side of city\n",
    "listings_1_df = listings_full_df[['id', 'neighbourhood', 'neighbourhood_cleansed', 'smart_location', 'property_type', 'room_type']].copy()\n",
    "\n",
    "european_n = ['Fatih', 'Zeytinburnu', 'Bakirkoy', 'Kucukcekmece', 'Avcilar', 'Bahcelievler', 'Arnavutkoy', 'Bagcilar', 'Basaksehir', 'Bayrampasar', 'Besiktas',\n",
    "             'Beylikduzu', 'Beyoglu', 'Buyukcekmece', 'Catalca', 'Esenler', 'Esenyurt', 'Eyup', 'Gaziosmanpasa', 'Gungoren', 'Kagithane', 'Sariyer', 'Silivri', 'Sisli',\n",
    "             'Sultangazi']\n",
    "asian_n = ['Atasehir', 'Beykoz', 'Cekmekoy', 'Kadikoy', 'Kartal', 'Maltepe', 'Pendik', 'Sancaktepe', 'Sile', 'Sultanbeyli', 'Tuzla', 'Umraniye', 'Uskudar']\n",
    "listings_1_df['Side'] = listings_1_df.neighbourhood_cleansed.apply(lambda x: 'European' if x in european_n else 'Asian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in dataset\n",
    "calendar_df = pd.read_csv(\"../Data/calendar.csv.gz\", low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out listings that have a min nights stay greater than 5\n",
    "calendar_fil_df = calendar_df.query(\"minimum_nights <= 5\").copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Â Convert date feature to date type and create new columns\n",
    "calendar_fil_df.date = pd.to_datetime(calendar_fil_df.date)\n",
    "calendar_fil_df['Month'] = calendar_fil_df.date.dt.month\n",
    "calendar_fil_df['MonthString'] = calendar_fil_df.Month.map({1: 'Jan', 2: 'Feb', 3: 'Mar', 4: 'Apr', 5: 'May', 6: 'Jun', 7: 'Jul', 8: 'Aug', 9: 'Sep', 10: 'Oct',\n",
    "                                                           11: 'Nov', 12: 'Dec'})\n",
    "calendar_fil_df['Year'] = calendar_fil_df.date.dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter ids that have missing price data and investigate\n",
    "id_w_missing_prices = calendar_fil_df.loc[calendar_fil_df.isnull().any(axis=1), 'listing_id'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows with missing price data\n",
    "calendar_fil_df = calendar_fil_df.dropna(subset=['price', 'adjusted_price'], how='any', axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new column that converts price to float type\n",
    "calendar_fil_df['adjusted_price_num'] = calendar_fil_df.adjusted_price.str.replace('[$,]', '').astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pivot table showing price for each month for each listing\n",
    "calendar_price_df = calendar_fil_df.pivot_table(index='listing_id', columns='MonthString', values='adjusted_price_num', aggfunc='mean').reset_index()\n",
    "calendar_price_df = calendar_price_df[['listing_id', 'Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge prepared listing and prepared calendar data ready for analysis of prices\n",
    "final_df_1 = listings_1_df.merge(calendar_price_df, how='inner', left_on='id', right_on='listing_id').drop(['listing_id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save dataset to csv\n",
    "#final_df_1.to_csv('../Data/DataPrepQ1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>summary</th>\n",
       "      <th>description</th>\n",
       "      <th>neighbourhood_cleansed</th>\n",
       "      <th>review_scores_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4826</td>\n",
       "      <td>My place is close to great views. My place is ...</td>\n",
       "      <td>My place is close to great views. My place is ...</td>\n",
       "      <td>Uskudar</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20815</td>\n",
       "      <td>Watch The Bosphorus from The Comfy Hill. A spa...</td>\n",
       "      <td>Watch The Bosphorus from The Comfy Hill. A spa...</td>\n",
       "      <td>Besiktas</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27271</td>\n",
       "      <td>This is a very nicely decorated apartment in a...</td>\n",
       "      <td>This is a very nicely decorated apartment in a...</td>\n",
       "      <td>Beyoglu</td>\n",
       "      <td>98.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28277</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The first advantage to stay in our apartments ...</td>\n",
       "      <td>Sisli</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28318</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Easy access to both bridges and just next to F...</td>\n",
       "      <td>Sariyer</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                            summary  \\\n",
       "0   4826  My place is close to great views. My place is ...   \n",
       "1  20815  Watch The Bosphorus from The Comfy Hill. A spa...   \n",
       "2  27271  This is a very nicely decorated apartment in a...   \n",
       "3  28277                                                NaN   \n",
       "4  28318                                                NaN   \n",
       "\n",
       "                                         description neighbourhood_cleansed  \\\n",
       "0  My place is close to great views. My place is ...                Uskudar   \n",
       "1  Watch The Bosphorus from The Comfy Hill. A spa...               Besiktas   \n",
       "2  This is a very nicely decorated apartment in a...                Beyoglu   \n",
       "3  The first advantage to stay in our apartments ...                  Sisli   \n",
       "4  Easy access to both bridges and just next to F...                Sariyer   \n",
       "\n",
       "   review_scores_rating  \n",
       "0                 100.0  \n",
       "1                  90.0  \n",
       "2                  98.0  \n",
       "3                   NaN  \n",
       "4                   NaN  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filter listings data and include certain columns\n",
    "listings_2_df = listings_full_df[['id', 'summary', 'description', 'neighbourhood_cleansed', 'review_scores_rating']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in dataset\n",
    "reviews_df = pd.read_csv(\"../Data/reviews.csv.gz\", low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge prepared listings data with reviews data ready for analysis of reviews file\n",
    "final_df_2 = reviews_df.merge(listings_2_df, how='inner', left_on='listing_id', right_on='id').drop(['id_x', 'id_y'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the daaset to csv\n",
    "#final_df_2.to_csv(\"../Data/DataPrepQ2.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
